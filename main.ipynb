{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b304b58",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --extra-index-url=https://pypi.celonis.cloud/ pycelonis==1.5.8 --user\n",
    "# !pip install -r requirements-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cc214",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %reload_ext autoreload\n",
    "\n",
    "# local module imports\n",
    "from utils import *\n",
    "from data_engineering import *\n",
    "from machine_learning import *\n",
    "from login import *\n",
    "import config\n",
    "\n",
    "# other imports\n",
    "from pycelonis import get_celonis\n",
    "import pandas as pd\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gc\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# mlflow configuation\n",
    "mlflow.set_experiment(f\"root_cause_analysis/{config.client}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4996a436",
   "metadata": {},
   "source": [
    "# Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "celonis = get_celonis(**login)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071da7b2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare global parameters\n",
    "datamodel = celonis.datamodels.find(config.datamodel_id)\n",
    "target_name = list(config.target.keys())[0]\n",
    "\n",
    "# Prepare table parameters    \n",
    "params_context = {\n",
    "    'datamodel': datamodel,\n",
    "    'case_key': config.case_key,\n",
    "    'target': config.target,\n",
    "    'filter': config.data_filter,\n",
    "    'tables_to_include': config.tables_to_include,\n",
    "    'additional_columns': config.additional_columns\n",
    "}\n",
    "params_act_count = {\n",
    "    'datamodel': datamodel,\n",
    "    'case_key': config.case_key,\n",
    "    'filter': config.data_filter,\n",
    "    'activity_table': config.activity_table,\n",
    "    'activity_name': config.activity_name\n",
    "}\n",
    "params_days_betw = {\n",
    "    'datamodel': datamodel,\n",
    "    'case_key': config.case_key,\n",
    "    'filter': config.data_filter,\n",
    "    'events_days_between': config.events_days_between,\n",
    "}\n",
    "params_mfeature = {\n",
    "    'datamodel': datamodel,\n",
    "    'case_key': config.case_key,\n",
    "    'filter': config.data_filter,\n",
    "    'multiple_value_features': config.multiple_value_features,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "if config.tables_to_include == {} and config.additional_columns == {}:\n",
    "    context_table = pd.DataFrame()\n",
    "else:\n",
    "    context_table = get_context_table(**params_context)\n",
    "if config.activity_table == None or  config.activity_name == None:\n",
    "    activity_count_table = pd.DataFrame()\n",
    "else:\n",
    "    activity_count_table = get_activity_count_table(**params_act_count)\n",
    "if config.events_days_between == {}:\n",
    "    days_between_table = pd.DataFrame()\n",
    "else:\n",
    "    days_between_table = get_days_between_table(**params_days_betw)\n",
    "if config.multiple_value_features == {}:\n",
    "    mfeature_table = pd.DataFrame()\n",
    "else:\n",
    "    mfeature_table = get_mfeature_count_table(**params_mfeature)\n",
    "    \n",
    "# Merge into one table\n",
    "input_table = pd.concat([context_table, days_between_table,activity_count_table,mfeature_table], axis=1, join=\"outer\")\n",
    "\n",
    "# Clean table\n",
    "input_table = drop_irrelevant_data(input_table,target_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e436024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory (delete single tables)\n",
    "del context_table\n",
    "del activity_count_table\n",
    "del days_between_table\n",
    "del mfeature_table\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2daf4",
   "metadata": {},
   "source": [
    "# Feature Selection (Random Forest Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list with all , categorical and numerical features\n",
    "features_rf, cat_features_rf, num_features_rf, features_with_target_rf = get_feature_lists(input_table,target_name)\n",
    "\n",
    "# Duplicate input_table (RF needs encoded categorical variables)\n",
    "input_table_rf = input_table.copy()\n",
    "\n",
    "# Handle missing values\n",
    "input_table_rf = handle_missing_data(input_table_rf,target_name)\n",
    "\n",
    "# Encode categorical variables\n",
    "input_table_rf = encode_cat_features(input_table_rf)\n",
    "\n",
    "# Get train/test set\n",
    "X_train_rf,X_test_rf,y_train_rf,y_test_rf = train_test_split(input_table_rf[features_rf],input_table_rf[target_name], test_size = config.test_size)\n",
    "\n",
    "# Define & train RandomForestClassifier\n",
    "rfc = RandomForestClassifier(**config.params_RandomForestClassifier)\n",
    "rfc.fit(X_train_rf,y_train_rf)\n",
    "\n",
    "# Get RF performance measures\n",
    "performance_metrics_rf = get_performance_measures(rfc, X_test_rf, y_test_rf)\n",
    "\n",
    "# Select features with RF feature importance\n",
    "selected_features = get_selected_features(rfc,X_train_rf, X_test_rf, y_test_rf, feature_importance_method= config.feature_importance_method, feature_number_to_select = config.feature_number_to_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe43f7",
   "metadata": {},
   "source": [
    "# Prediction Model (CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Reduce input_table by selected features + target\n",
    "    if target_name not in selected_features:\n",
    "        selected_features.append(target_name)\n",
    "    input_table = input_table[selected_features]\n",
    "\n",
    "    # Get feature lists by category\n",
    "    features, cat_features, num_features, features_with_target = get_feature_lists(input_table,target_name)\n",
    "\n",
    "    # Handle missing cat features\n",
    "    input_table[cat_features] = input_table[cat_features].fillna('missing')\n",
    "\n",
    "    # Get train/test set\n",
    "    X_train,X_test,y_train,y_test = train_test_split(input_table[features],input_table[target_name], test_size=config.test_size)\n",
    "\n",
    "    # Define train/test pool\n",
    "    train_pool = Pool(X_train, \n",
    "                      y_train, \n",
    "                      cat_features\n",
    "                     )\n",
    "\n",
    "    test_pool = Pool(X_test,\n",
    "                     y_test,\n",
    "                     cat_features\n",
    "                     )\n",
    "\n",
    "    # Specify the training parameters manually\n",
    "    if config.grid_search==False:\n",
    "        model = CatBoostClassifier(**config.params_CatBoostClassifier)\n",
    "        for key, val in config.params_CatBoostClassifier.items():\n",
    "            mlflow.log_param(key, val)\n",
    "\n",
    "    # Specify the training parameters through grid search\n",
    "    else:\n",
    "        model,grid_search_result = get_grid_search_results(input_table, target_name, features, cat_features, train_pool, **config.params_grid_search)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_pool\n",
    "              ,eval_set=test_pool\n",
    "              ,**config.params_fit_CatBoost    \n",
    "             )\n",
    "    for key, val in config.params_fit_CatBoost.items():\n",
    "        mlflow.log_param(key, val)\n",
    "\n",
    "    # Get catBoost performance measures\n",
    "    performance_metrics = get_performance_measures(model, X_test, y_test)\n",
    "    for key, val in performance_metrics.items():\n",
    "        mlflow.log_metric(key, val)\n",
    "        \n",
    "    mlflow.catboost.log_model(model, 'RCA_model')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bda581",
   "metadata": {},
   "source": [
    "# Model Explanation (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Prepare variables\n",
    "X = X_train.append(X_test)\n",
    "y = y_train.append(y_test)\n",
    "pool = Pool(X, y, cat_features)\n",
    "\n",
    "# Create shap_table, reason_table, top_reasons, stat_table\n",
    "shap_table = get_shapley_value_table(input_table, target_name, model, X, y, summary_plot = False)\n",
    "reason_table, top_reasons = get_reasons(shap_table, input_table, target_name, amount = config.cause_number_to_identify, datamodel=None)\n",
    "stat_table = get_stat_table(input_table, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f75a92",
   "metadata": {},
   "source": [
    "## Save/Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab12375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save DataFrame\n",
    "# input_table.to_pickle('input_table.pkl')\n",
    "\n",
    "# # Load DataFrame\n",
    "# input_table = pd.read_pickle('input_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data to CSV files\n",
    "# Save output tables as .csv files\n",
    "# shap_table.round(4).to_csv('shap_table.csv')\n",
    "# reason_table.to_csv('reason_table.csv')\n",
    "# top_reasons.to_csv('top_reasons.csv')\n",
    "# stat_table.to_csv('stat_table.csv')\n",
    "# selected_features_df = pd.DataFrame(selected_features)\n",
    "# selected_features_df.to_csv('selected_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309208b",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
